{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем библиотеки\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.resnet_v2 import ResNet152V2\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.densenet import DenseNet169\n",
    "# from keras.applications.efficientnet import EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Текущий каталог с проектом\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "type(current_dir)\n",
    "\n",
    "# Каталог с набором данных\n",
    "data_dir = current_dir + \"\\\\dogs-vs-cats\\\\train\"\n",
    "\n",
    "# Каталог с данными для обучения\n",
    "train_dir = current_dir + \"\\\\train\"\n",
    "\n",
    "# Каталог с данными для проверки\n",
    "val_dir = current_dir + \"\\\\val\"\n",
    "\n",
    "# Каталог с данными для тестирования\n",
    "test_dir = current_dir + \"\\\\test\"\n",
    "\n",
    "# Количество элементов данных в одном классе\n",
    "nb_images = 12500\n",
    "\n",
    "# Размеры изображения\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# backend Tensorflow, channels_last\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Размер мини-выборки\n",
    "batch_size = 16\n",
    "\n",
    "# Количество изображений для обучения\n",
    "nb_train_samples = 17500\n",
    "\n",
    "# Количество изображений для проверки\n",
    "nb_validation_samples = 3750\n",
    "\n",
    "# Количество изображений для тестирования\n",
    "nb_test_samples = 3750\n",
    "\n",
    "epochs = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNetDict(weights, include_top, input_shape):\n",
    "    list = {\n",
    "        'VGG16' : VGG16(weights = weights, include_top= include_top, input_shape = input_shape),\n",
    "        'Xception' : Xception(weights = weights, include_top= include_top, input_shape = input_shape),\n",
    "        'VGG19' : VGG19(weights = weights, include_top= include_top, input_shape = input_shape),\n",
    "        'ResNet50' : ResNet50(weights = weights, include_top= include_top, input_shape = input_shape),\n",
    "        'InceptionV3' : InceptionV3(weights = weights, include_top= include_top, input_shape = input_shape),\n",
    "        'InceptionResNetV2' : InceptionResNetV2(weights = weights, include_top= include_top, input_shape = input_shape),\n",
    "        'MobileNet' : MobileNet(weights = weights, include_top= include_top, input_shape = input_shape),\n",
    "        'MobileNetV2' : MobileNetV2(weights = weights, include_top= include_top, input_shape = input_shape),\n",
    "        'DenseNet169' : DenseNet169(weights = weights, include_top= include_top, input_shape = input_shape)\n",
    "    }\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n",
      "C:\\Users\\artig\\Anaconda3\\envs\\univer\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "C:\\Users\\artig\\Anaconda3\\envs\\univer\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "C:\\Users\\artig\\Anaconda3\\envs\\univer\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "NetDict = GetNetDict(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17500 images belonging to 2 classes.\n",
      "Found 3750 images belonging to 2 classes.\n",
      "Found 3750 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Создаем генератор изображений \n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Генератор данных для обучения на основе изображений из каталога\n",
    "train_generator = datagen.flow_from_directory(\n",
    " train_dir,\n",
    " target_size=(img_width, img_height),\n",
    " batch_size=batch_size,\n",
    " class_mode='binary')\n",
    "\n",
    "# Генератор данных для проверки на основе изображений из каталога\n",
    "val_generator = datagen.flow_from_directory(\n",
    " val_dir,\n",
    " target_size=(img_width, img_height),\n",
    " batch_size=batch_size,\n",
    " class_mode='binary')\n",
    "\n",
    "# Генератор данных для тестирования на основе изображений из каталога\n",
    "test_generator = datagen.flow_from_directory(\n",
    " test_dir,\n",
    " target_size=(img_width, img_height),\n",
    " batch_size=batch_size,\n",
    " class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FreezeWeghts(Net):\n",
    "    Net.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Замораживаем\" веса предварительно обученной нейронной сети VGG16\n",
    "for net in NetDict.items():\n",
    "    FreezeWeghts(net[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateCompositeModel(Net):\n",
    "    # Создаем составную нейронную сеть на основе VGG16\n",
    "    model = Sequential()\n",
    "\n",
    "    # Добавляем в модель сеть VGG16 вместо слоя\n",
    "    model.add(Net)\n",
    "\n",
    "    # Слой преобразования данных из 2D представления в плоское\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Полносвязный слой для классификации\n",
    "    model.add(Dense(256,  activation = 'relu'))\n",
    "\n",
    "    # Слой регуляризации Dropout \n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Выходной полносвязный слой\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               13107456  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 33,969,193\n",
      "Trainable params: 13,107,713\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 22,122,049\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 5, 5, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               13107456  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 36,695,425\n",
      "Trainable params: 13,107,713\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               4718848   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 26,521,889\n",
      "Trainable params: 4,719,105\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 3, 3, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 57,876,193\n",
      "Trainable params: 3,539,457\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 4, 4, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 7,423,681\n",
      "Trainable params: 4,194,817\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 5, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               8192256   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 10,450,497\n",
      "Trainable params: 8,192,513\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet169 (Model)          (None, 4, 4, 1664)        12642880  \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 26624)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               6816000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 19,459,137\n",
      "Trainable params: 6,816,257\n",
      "Non-trainable params: 12,642,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CompositeModelDict = {}\n",
    "for net in NetDict.items():\n",
    "    CompositeModelDict.update({net[0] : CreateCompositeModel(net[1])})\n",
    "    \n",
    "for item in CompositeModelDict.items():\n",
    "    item[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Компилируем составную нейронную сеть\n",
    "def CompileNet(Net):\n",
    "    Net.compile(loss='binary_crossentropy',\n",
    "     optimizer='adam',\n",
    "     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in CompositeModelDict.items():\n",
    "    CompileNet(net[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitNet(Net):\n",
    "    Net.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16\n",
      "Epoch 1/2\n",
      "1093/1093 [==============================] - 200s 183ms/step - loss: 0.3029 - acc: 0.8656 - val_loss: 0.2256 - val_acc: 0.9079\n",
      "Epoch 2/2\n",
      "1093/1093 [==============================] - 196s 179ms/step - loss: 0.2426 - acc: 0.8974 - val_loss: 0.2185 - val_acc: 0.9089\n",
      "Xception\n",
      "Epoch 1/2\n",
      "1093/1093 [==============================] - 157s 144ms/step - loss: 1.1549 - acc: 0.8167 - val_loss: 0.1534 - val_acc: 0.9623\n",
      "Epoch 2/2\n",
      "1093/1093 [==============================] - 131s 120ms/step - loss: 0.2964 - acc: 0.8756 - val_loss: 0.1805 - val_acc: 0.9545\n",
      "VGG19\n",
      "Epoch 1/2\n",
      "1093/1093 [==============================] - 258s 236ms/step - loss: 0.3644 - acc: 0.8402 - val_loss: 0.2713 - val_acc: 0.8809\n",
      "Epoch 2/2\n",
      "1093/1093 [==============================] - 248s 227ms/step - loss: 0.2888 - acc: 0.8775 - val_loss: 0.2641 - val_acc: 0.8907\n",
      "ResNet50\n",
      "Epoch 1/2\n",
      "1093/1093 [==============================] - 148s 136ms/step - loss: 1.7703 - acc: 0.8797 - val_loss: 8.0504 - val_acc: 0.5005\n",
      "Epoch 2/2\n",
      "1093/1093 [==============================] - 129s 118ms/step - loss: 1.6440 - acc: 0.8936 - val_loss: 6.4623 - val_acc: 0.5003\n",
      "InceptionV3\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 788 of 2063 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 573/1093 [==============>...............] - ETA: 54s - loss: 0.5945 - acc: 0.7690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1304 of 2063 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 145s 132ms/step - loss: 0.4959 - acc: 0.7967 - val_loss: 0.2327 - val_acc: 0.9447\n",
      "Epoch 2/2\n",
      "1092/1093 [============================>.] - ETA: 0s - loss: 0.3688 - acc: 0.8321"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 973 of 1112 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 101s 92ms/step - loss: 0.3689 - acc: 0.8320 - val_loss: 0.1836 - val_acc: 0.9507\n",
      "InceptionResNetV2\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1092 of 4441 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2753 of 4441 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 752/1093 [===================>..........] - ETA: 47s - loss: 0.4535 - acc: 0.8305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 855 of 4441 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2526 of 4441 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 4178 of 4441 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092/1093 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1717 of 2500 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 198s 181ms/step - loss: 0.4134 - acc: 0.8386 - val_loss: 0.2065 - val_acc: 0.9663\n",
      "Epoch 2/2\n",
      "1092/1093 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.8757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1462 of 2500 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 155s 142ms/step - loss: 0.2866 - acc: 0.8758 - val_loss: 0.1745 - val_acc: 0.9625\n",
      "MobileNet\n",
      "Epoch 1/2\n",
      "1093/1093 [==============================] - 86s 79ms/step - loss: 0.4472 - acc: 0.9084 - val_loss: 0.1143 - val_acc: 0.9653\n",
      "Epoch 2/2\n",
      "1093/1093 [==============================] - 67s 61ms/step - loss: 0.1773 - acc: 0.9304 - val_loss: 0.0995 - val_acc: 0.9665\n",
      "MobileNetV2\n",
      "Epoch 1/2\n",
      "1093/1093 [==============================] - 110s 101ms/step - loss: 1.8556 - acc: 0.8670 - val_loss: 1.5998 - val_acc: 0.89588545 - acc: 0.86\n",
      "Epoch 2/2\n",
      "1093/1093 [==============================] - 81s 74ms/step - loss: 1.6297 - acc: 0.8911 - val_loss: 1.2636 - val_acc: 0.9194\n",
      "DenseNet169\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 836 of 3966 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2200 of 3966 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3621 of 3966 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 847/1093 [======================>.......] - ETA: 58s - loss: 7.9569 - acc: 0.5004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 872 of 3966 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2299 of 3966 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3821 of 3966 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092/1093 [============================>.] - ETA: 0s - loss: 7.9707 - acc: 0.4996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 802 of 2172 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 363s 332ms/step - loss: 7.9698 - acc: 0.4997 - val_loss: 7.9669 - val_acc: 0.5003\n",
      "Epoch 2/2\n",
      "1092/1093 [============================>.] - ETA: 0s - loss: 7.9669 - acc: 0.5003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1531 of 2172 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1093/1093 [==============================] - 230s 211ms/step - loss: 7.9669 - acc: 0.5003 - val_loss: 7.9755 - val_acc: 0.4997\n"
     ]
    }
   ],
   "source": [
    "for net in CompositeModelDict.items():\n",
    "    print(net[0])\n",
    "    FitNet(net[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveNet(NetName, Net):\n",
    "    ## Сохраняем обученную нейронную сеть\n",
    "    model_json = Net.to_json()\n",
    "    json_file = open(\"dogs-vs-cats-model\" + NetName + \".json\", \"w\")\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "    Net.save_weights(\"dogs-vs-cats-model\" + NetName + \"gpu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in CompositeModelDict.items():\n",
    "    SaveNet(net[0], net[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оставшиеся две сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем библиотеки\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.python.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.python.keras.applications.efficientnet import EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234553344/234545216 [==============================] - 26s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
      "165240832/165234480 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "Resnet = ResNet152V2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "Efficient = EfficientNetB6(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resnet.trainable = False\n",
    "Efficient.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resnet_model = CreateCompositeModel(Resnet)\n",
    "Efficient_model = CreateCompositeModel(Efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileNet(Resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileNet(Efficient_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 1275s 1s/step - loss: 0.5111 - accuracy: 0.9535 - val_loss: 0.1291 - val_accuracy: 0.9631\n",
      "1093/1093 [==============================] - 1154s 1s/step - loss: 1.1665 - accuracy: 0.4923 - val_loss: 0.6931 - val_accuracy: 0.4997\n"
     ]
    }
   ],
   "source": [
    "FitNet(Resnet_model)\n",
    "FitNet(Efficient_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveNet('ResNet152V2', Resnet_model)\n",
    "SaveNet('EfficientNetB6', Efficient_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
